# -*- coding: utf-8 -*-
"""GNN Graphs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15E3--fllX99mbQ7KlVDzcO7E1vvSfv-3
"""

import torch
import torch.nn as nn
import networkx as nx
import random
import numpy as np
from torch.utils.data import Dataset, DataLoader
from transformers import BertConfig, BertModel
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pandas as pd
import time
import warnings
warnings.filterwarnings('ignore')

# Set seeds for reproducibility
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

# Load and prepare graph data
def prepare_graph_data():
    G = nx.karate_club_graph()
    labels = [G.nodes[node]['club'] for node in G.nodes()]
    label_encoder = LabelEncoder()
    encoded_labels = label_encoder.fit_transform(labels)
    num_classes = len(label_encoder.classes_)
    one_hot_labels = torch.eye(num_classes)[encoded_labels]
    return G, one_hot_labels, label_encoder, num_classes

# Generate walks for the first model (one-hot labels)
def generate_label_walks(G, one_hot_labels, num_walks=5, walk_length=8):
    walks = []
    for _ in range(num_walks):
        for node in G.nodes():
            walk = [one_hot_labels[node]]
            current = node
            for _ in range(walk_length - 1):
                neighbors = list(G.neighbors(current))
                if not neighbors:
                    break
                current = random.choice(neighbors)
                walk.append(one_hot_labels[current])
            walks.append(torch.stack(walk))
    return walks

# Dataset class for the first model
class LabelWalkDataset(Dataset):
    def __init__(self, walks, seq_length=4):
        self.seq_length = seq_length
        self.examples = []
        for walk in walks:
            for i in range(len(walk) - seq_length):
                input_seq = walk[i:i+seq_length]
                target = walk[i+seq_length].argmax()
                self.examples.append((input_seq, target))

    def __len__(self):
        return len(self.examples)

    def __getitem__(self, idx):
        return {
            'input_features': self.examples[idx][0].float(),
            'labels': self.examples[idx][1]
        }

# 5. BERT model adapted for one-hot inputs
class BertEncoder(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        # Project one-hot vectors to BERT's hidden size
        self.projection = nn.Linear(num_classes, 768)

        # Initialize BERT
        config = BertConfig(
            hidden_size=768,
            num_attention_heads=4,
            num_hidden_layers=2

        )
        self.bert = BertModel(config)

        # Classifier head
        self.classifier = nn.Linear(768, num_classes)

    def forward(self, input_features, labels=None):
        # input_features shape: [batch, seq_len, num_classes]
        projected = self.projection(input_features)  # [batch, seq_len, 768]

        # BERT processing
        outputs = self.bert(
            inputs_embeds=projected,
            attention_mask=torch.ones(projected.shape[:2], device=input_features.device))

        # Use [CLS] token for classification
        logits = self.classifier(outputs.last_hidden_state[:, 0, :])

        loss = None
        if labels is not None:
            loss = nn.CrossEntropyLoss()(logits, labels)
        return {'logits': logits, 'loss': loss}

# Evaluation function for the first model
def evaluate_model(model, dataloader, device):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for batch in dataloader:
            inputs = batch['input_features'].to(device)
            targets = batch['labels'].to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs['logits'], 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(targets.cpu().numpy())

    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)
    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)

    return accuracy, precision, recall, f1

# Function to run experiments with different parameters
def run_experiments(num_walks_list, walk_lengths_list, num_epochs=10):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    G, one_hot_labels, label_encoder, num_classes = prepare_graph_data()

    results = []

    for num_walks in num_walks_list:
        for walk_length in walk_lengths_list:
            if walk_length < 5:  # Minimum walk length for sequence prediction
                continue

            print(f"Testing with {num_walks} walks and walk length {walk_length}")

            # Generate walks
            set_seed()
            walks = generate_label_walks(G, one_hot_labels, num_walks, walk_length)

            # Split into train and test
            train_walks, test_walks = train_test_split(walks, test_size=0.3, random_state=42)

            # Create datasets and dataloaders
            train_dataset = LabelWalkDataset(train_walks)
            test_dataset = LabelWalkDataset(test_walks)

            train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
            test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            # Initialize model
            model = BertEncoder(num_classes).to(device)
            optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)

            # Training loop
            train_losses = []
            start_time = time.time()

            for epoch in range(num_epochs):
                model.train()
                total_loss = 0
                for batch in train_dataloader:
                    inputs = batch['input_features'].to(device)
                    targets = batch['labels'].to(device)

                    outputs = model(inputs, targets)
                    loss = outputs['loss']

                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    total_loss += loss.item()

                avg_loss = total_loss / len(train_dataloader)
                train_losses.append(avg_loss)

            training_time = time.time() - start_time
# Evaluation
            accuracy, precision, recall, f1 = evaluate_model(model, test_dataloader, device)

             # Store results
            results.append({
                'num_walks': num_walks,
                'walk_length': walk_length,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'training_time': training_time,
                'final_loss': train_losses[-1],
                'num_samples': len(train_walks) + len(test_walks)
            })

            print(f"Results: Accuracy={accuracy:.4f}, F1={f1:.4f}, Time={training_time:.2f}s")

    return pd.DataFrame(results)

# Function to visualize results
def visualize_results(results_df):
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('Performance Metrics vs. Number of Walks and Walk Length', fontsize=16)
        # Accuracy
    pivot_acc = results_df.pivot(index='num_walks', columns='walk_length', values='accuracy')
    sns.heatmap(pivot_acc, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[0, 0])
    axes[0, 0].set_title('Accuracy')

    # F1 Score
    pivot_f1 = results_df.pivot(index='num_walks', columns='walk_length', values='f1_score')
    sns.heatmap(pivot_f1, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[0, 1])
    axes[0, 1].set_title('F1 Score')

    # Training Time
    pivot_time = results_df.pivot(index='num_walks', columns='walk_length', values='training_time')
    sns.heatmap(pivot_time, annot=True, fmt='.1f', cmap='YlOrRd', ax=axes[0, 2])
    axes[0, 2].set_title('Training Time (s)')

    # Precision
    pivot_prec = results_df.pivot(index='num_walks', columns='walk_length', values='precision')
    sns.heatmap(pivot_prec, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[1, 0])
    axes[1, 0].set_title('Precision')

    # Recall
    pivot_rec = results_df.pivot(index='num_walks', columns='walk_length', values='recall')
    sns.heatmap(pivot_rec, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[1, 1])
    axes[1, 1].set_title('Recall')

    # Final Loss
    pivot_loss = results_df.pivot(index='num_walks', columns='walk_length', values='final_loss')
    sns.heatmap(pivot_loss, annot=True, fmt='.3f', cmap='YlOrRd_r', ax=axes[1, 2])
    axes[1, 2].set_title('Final Loss')

    plt.tight_layout()
    plt.show()

    # Line plots for trends
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # Accuracy by walk length for different numbers of walks
    for num_walks in results_df['num_walks'].unique():
        subset = results_df[results_df['num_walks'] == num_walks]
        axes[0, 0].plot(subset['walk_length'], subset['accuracy'], 'o-', label=f'{num_walks} walks')
    axes[0, 0].set_xlabel('Walk Length')
    axes[0, 0].set_ylabel('Accuracy')
    axes[0, 0].set_title('Accuracy vs. Walk Length')
    axes[0, 0].legend()
    axes[0, 0].grid(True)

    # F1 score by number of walks for different walk lengths
    for walk_length in results_df['walk_length'].unique():
        subset = results_df[results_df['walk_length'] == walk_length]
        axes[0, 1].plot(subset['num_walks'], subset['f1_score'], 'o-', label=f'Length {walk_length}')
    axes[0, 1].set_xlabel('Number of Walks')
    axes[0, 1].set_ylabel('F1 Score')
    axes[0, 1].set_title('F1 Score vs. Number of Walks')
    axes[0, 1].legend()
    axes[0, 1].grid(True)

    # Training time by number of walks
    for walk_length in results_df['walk_length'].unique():
        subset = results_df[results_df['walk_length'] == walk_length]
        axes[1, 0].plot(subset['num_walks'], subset['training_time'], 'o-', label=f'Length {walk_length}')
    axes[1, 0].set_xlabel('Number of Walks')
    axes[1, 0].set_ylabel('Training Time (s)')
    axes[1, 0].set_title('Training Time vs. Number of Walks')
    axes[1, 0].legend()
    axes[1, 0].grid(True)

    # Sample efficiency
    axes[1, 1].scatter(results_df['num_samples'], results_df['accuracy'], alpha=0.7)
    axes[1, 1].set_xlabel('Number of Samples')
    axes[1, 1].set_ylabel('Accuracy')
    axes[1, 1].set_title('Sample Efficiency')
    axes[1, 1].grid(True)

    # Add trend line for sample efficiency
    z = np.polyfit(results_df['num_samples'], results_df['accuracy'], 1)
    p = np.poly1d(z)
    axes[1, 1].plot(results_df['num_samples'], p(results_df['num_samples']), "r--", alpha=0.8)

    plt.tight_layout()
    plt.show()

    return results_df

# Main execution
if __name__ == "__main__":
    # Define parameter ranges to test
    num_walks_list = [5, 15, 25, 35, 45, 55, 65, 75]
    walk_lengths_list = [5, 10, 15, 20, 25, 30]

    # Run experiments
    print("Starting experiments...")
    results_df = run_experiments(num_walks_list, walk_lengths_list, num_epochs=10)

    # Display and visualize results
    print("\nExperiment Results:")
    print(results_df.to_string(index=False))

    # Visualize results
    visualize_results(results_df)

# Find best parameters
    best_by_accuracy = results_df.loc[results_df['accuracy'].idxmax()]
    best_by_f1 = results_df.loc[results_df['f1_score'].idxmax()]
    best_efficiency = results_df.loc[(results_df['accuracy'] / results_df['training_time']).idxmax()]

    print("\nBest Parameters:")
    print(f"By Accuracy: {best_by_accuracy['num_walks']} walks, length {best_by_accuracy['walk_length']} (Accuracy: {best_by_accuracy['accuracy']:.4f})")
    print(f"By F1 Score: {best_by_f1['num_walks']} walks, length {best_by_f1['walk_length']} (F1: {best_by_f1['f1_score']:.4f})")
    print(f"By Efficiency: {best_efficiency['num_walks']} walks, length {best_efficiency['walk_length']} (Accuracy/Time: {best_efficiency['accuracy']/best_efficiency['training_time']:.4f})")

"""For Second model"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install python-igraph

import igraph as ig

"""The error `ModuleNotFoundError: No module named 'igraph'` indicates that the required `igraph` library is not installed in your environment.

To fix this, you need to install the `python-igraph` package. The following cell will install the necessary library.
"""

# Generate feature-label walks for the second model
def generate_feature_label_walks(G, features, encoded_labels, num_walks=5, walk_length=8):
    pairs = []
    for _ in range(num_walks):
        for node in G.nodes():
            f_seq = [features[node]]
            l_seq = [encoded_labels[node]]
            cur = node
            for _ in range(walk_length - 1):
                nbrs = list(G.neighbors(cur))
                if not nbrs:
                    break
                cur = random.choice(nbrs)
                f_seq.append(features[cur])
                l_seq.append(int(encoded_labels[cur]))
            if len(f_seq) == walk_length:
                pairs.append((np.stack(f_seq, axis=0), np.array(l_seq, dtype=np.int64)))
    return pairs

# Dataset class for the second model
class CentralityToLabelDataset(Dataset):
    def __init__(self, pairs):
        self.pairs = pairs

    def __len__(self):
        return len(self.pairs)

    def __getitem__(self, idx):
        x, y = self.pairs[idx]
        return {"x": torch.tensor(x, dtype=torch.float32), "y": torch.tensor(y, dtype=torch.long)}

# Seq2Seq model with BERT encoder
class Seq2SeqBERT(nn.Module):
    def __init__(self,
                 input_dim: int,
                 num_classes: int,
                 walk_length: int, # Add walk_length as an argument
                 hidden_dim: int = 64,
                 num_layers: int = 1,
                 nhead: int = 2,
                 dropout_rate: float = 0.1):

        super().__init__()
        self.num_classes = num_classes
        self.hidden_dim  = hidden_dim
        self.max_len     = walk_length # Use walk_length here
        self.dropout = nn.Dropout(dropout_rate)

        # ----- Encoder (BERT) -----
        self.src_proj = nn.Linear(input_dim, hidden_dim)  # project features -> hidden
        enc_cfg = BertConfig(
            hidden_size=hidden_dim,
            num_attention_heads=nhead,
            num_hidden_layers=num_layers,
            intermediate_size=hidden_dim * 4,
            add_cross_attention=False,
            hidden_dropout_prob=dropout_rate,
            attention_probs_dropout_prob=dropout_rate
        )
        self.encoder = BertModel(enc_cfg)

        # ----- Decoder (Transformer) -----
        self.decoder_layer = nn.TransformerDecoderLayer(
            d_model=hidden_dim, nhead=nhead, dim_feedforward=hidden_dim * 4, batch_first=False, dropout=dropout_rate
        )
        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)

        # Label token embedding (+1 for BOS)
        self.BOS_IDX = num_classes
        self.tok_embed = nn.Embedding(num_embeddings=num_classes + 1, embedding_dim=hidden_dim)

        # Learnable positional embeddings for decoder
        self.pos_embed = nn.Embedding(num_embeddings=self.max_len, embedding_dim=hidden_dim) # Use self.max_len here

        # Final classifier (hidden -> label logits)
        self.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_dim, num_classes)
        )

    def _causal_mask(self, T: int, device):
        # Prevent attending to future tokens at the decoder
        return nn.Transformer.generate_square_subsequent_mask(T).to(device)

    def forward(self, src_feats: torch.Tensor, tgt_in: torch.Tensor):
        """
        Training with teacher-forcing.
        src_feats: [B, S, F]  - feature sequence
        tgt_in:    [B, T]     - decoder input tokens (BOS + gold[:-1])
        Returns logits: [B, T, C]
        """
        B, S, F = src_feats.shape
        _, T    = tgt_in.shape

        # Apply dropout to input features
        src_feats = self.dropout(src_feats)

        # ----- Encode source -----
        src_proj = self.src_proj(src_feats)                     # [B, S, H]
        src_mask = torch.ones(B, S, device=src_feats.device)    # all valid tokens
        enc_out  = self.encoder(inputs_embeds=src_proj,
                                attention_mask=src_mask).last_hidden_state  # [B, S, H]
        enc_out  = enc_out.transpose(0, 1)                      # -> [S, B, H] for decoder

        # ----- Prepare decoder inputs (tokens + positions) -----
        tok_emb = self.tok_embed(tgt_in)                        # [B, T, H]
        pos_ids = torch.arange(T, device=src_feats.device).unsqueeze(0).expand(B, T)
        dec_in  = (tok_emb + self.pos_embed(pos_ids)).transpose(0, 1)  # [T, B, H]

        # Causal mask for autoregression
        tgt_mask = self._causal_mask(T, device=src_feats.device)

        # ----- Decode -----
        dec_out = self.decoder(dec_in, enc_out, tgt_mask=tgt_mask)  # [T, B, H]
        dec_out = self.dropout(dec_out)
        logits  = self.classifier(dec_out.transpose(0, 1))          # [B, T, C]
        return logits

    @torch.no_grad()
    def generate(self, src_feats: torch.Tensor, max_new_tokens: int, beam_width: int = 1):
        """
        Greedy decoding (beam_width=1) or Beam search.
        src_feats: [B, S, F]
        Returns predicted labels: [B, max_new_tokens]
        """
        B, S, F = src_feats.shape
        device  = src_feats.device

        # Encode source (repeat for beam search)
        src_proj = self.src_proj(src_feats)                     # [B, S, H]
        src_mask = torch.ones(B, S, device=device)
        enc_out  = self.encoder(inputs_embeds=src_proj,
                                attention_mask=src_mask).last_hidden_state
        enc_out  = enc_out.transpose(0, 1)                      # [S, B, H]

        # Initialize beams
        # Each beam is a tuple: (sequence_of_tokens, log_probability)
        beams = [[(torch.full((1, 1), self.BOS_IDX, dtype=torch.long, device=device), 0.0)] for _ in range(B)]

        # Autoregressively append tokens
        for _ in range(max_new_tokens):
            next_beams = [[] for _ in range(B)]
            for batch_idx in range(B):
                for seq, log_prob in beams[batch_idx]:
                    T = seq.size(1)
                    tok_emb = self.tok_embed(seq)                        # [1, T, H]
                    pos_ids = torch.arange(T, device=device).unsqueeze(0).expand(1, T)
                    dec_in  = (tok_emb + self.pos_embed(pos_ids)).transpose(0, 1)  # [T, 1, H]

                    # Select corresponding encoder output for this beam
                    enc_out_beam = enc_out[:, batch_idx, :].unsqueeze(1) # [S, 1, H]

                    tgt_mask = self._causal_mask(T, device=device)

                    dec_out = self.decoder(dec_in, enc_out_beam, tgt_mask=tgt_mask)  # [T, 1, H]
                    step_logits = self.classifier(dec_out[-1])                  # [1, C]
                    log_probs = torch.log_softmax(step_logits, dim=-1)          # [1, C]

                    # Expand beam
                    topk_log_probs, topk_indices = torch.topk(log_probs, beam_width, dim=-1)

                    for k in range(beam_width):
                        next_token = topk_indices[0, k].unsqueeze(0).unsqueeze(0) # [1, 1]
                        new_seq = torch.cat([seq, next_token], dim=1)             # [1, T+1]
                        new_log_prob = log_prob + topk_log_probs[0, k].item()
                        next_beams[batch_idx].append((new_seq, new_log_prob))

                # Select top beam_width sequences for this batch item
                next_beams[batch_idx].sort(key=lambda x: x[1], reverse=True)
                beams[batch_idx] = next_beams[batch_idx][:beam_width]

        # Return the best sequence from each beam (highest log probability)
        final_sequences = torch.cat([beam[0][0] for beam in beams], dim=0)
        return final_sequences[:, 1:]  # drop BOS

# Evaluation function for the second model
def evaluate_seq2seq_model(model, dataloader, device, num_classes):
    model.eval()
    all_true = []
    all_preds = []

    with torch.no_grad():
        for batch in dataloader:
            x = batch["x"].to(device)
            y_true = batch["y"].to(device)

            # Generate predictions
            preds = model.generate(x, max_new_tokens=y_true.size(1))


            # Store for metrics calculation
            all_true.extend(y_true.cpu().numpy())
            all_preds.extend(preds.cpu().numpy())

    # Convert to numpy arrays
    all_true = np.array(all_true)
    all_preds = np.array(all_preds)

    # Calculate metrics
    token_accuracy = np.mean(all_true == all_preds)
    sequence_accuracy = np.mean(np.all(all_true == all_preds, axis=1))

    # Flatten for overall metrics
    flat_true = all_true.flatten()
    flat_preds = all_preds.flatten()

    accuracy = accuracy_score(flat_true, flat_preds)
    precision = precision_score(flat_true, flat_preds, average='weighted', zero_division=0)
    recall = recall_score(flat_true, flat_preds, average='weighted', zero_division=0)
    f1 = f1_score(flat_true, flat_preds, average='weighted', zero_division=0)

    return accuracy, precision, recall, f1, token_accuracy, sequence_accuracy

# Load and prepare graph data with centrality features
def prepare_graph_data_with_features():
    # Load networkx graph
    G = nx.karate_club_graph()
    labels = [G.nodes[node]['club'] for node in G.nodes()]
    label_encoder = LabelEncoder()
    encoded_labels = label_encoder.fit_transform(labels)
    num_classes = len(label_encoder.classes_)

    # Load igraph for centrality features
    g = ig.Graph.Famous("Zachary")

    # Add club labels to igraph (to match networkx)
    for i, node in enumerate(g.vs):
        node['club'] = labels[i]

    # Calculate centrality measures
    g.vs["degree"] = g.degree()
    g.vs["betweenness"] = g.betweenness()
    g.vs["closeness"] = g.closeness()
    g.vs["eigenvector"] = g.eigenvector_centrality()
    g.vs["pagerank"] = g.pagerank()
    communities = g.community_multilevel()
    g.vs["community"] = communities.membership

    # Build feature matrix [N, F]
    features = np.array([
        [v["degree"], v["betweenness"], v["closeness"],
         v["eigenvector"], v["pagerank"], v["community"]]
        for v in g.vs
    ], dtype=np.float32)

    return G, features, encoded_labels, label_encoder, num_classes

def run_seq2seq_experiments(num_walks_list, walk_lengths_list, num_epochs=10):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    G, features, encoded_labels, label_encoder, num_classes = prepare_graph_data_with_features()

    results = []

    for num_walks in num_walks_list:
        for walk_length in walk_lengths_list:
            if walk_length < 5:  # Minimum walk length
                continue

            print(f"Testing with {num_walks} walks and walk length {walk_length}")

            # Generate walks
            set_seed()
            pairs = generate_feature_label_walks(G, features, encoded_labels, num_walks, walk_length)

            # Split into train/val/test (70%/15%/15%)
            train_pairs, temp_pairs = train_test_split(pairs, test_size=0.30, random_state=42)
            val_pairs, test_pairs = train_test_split(temp_pairs, test_size=0.50, random_state=42)

            # Scale features based on training set
            train_feats = np.vstack([x for x, _ in train_pairs])
            scaler = MinMaxScaler().fit(train_feats)

            def scale_pairs(pairs, scaler):
                return [(scaler.transform(x), y) for x, y in pairs]

            train_pairs = scale_pairs(train_pairs, scaler)
            val_pairs = scale_pairs(val_pairs, scaler)
            test_pairs = scale_pairs(test_pairs, scaler)

            # Calculate class weights
            all_train_labels = []
            for x, y in train_pairs:
                all_train_labels.extend(y)
            class_counts = torch.bincount(torch.tensor(all_train_labels))
            class_weights = 1.0 / class_counts.float()
            class_weights = class_weights / class_weights.sum() * len(class_weights)

            # Create data loaders
            train_loader = DataLoader(CentralityToLabelDataset(train_pairs), batch_size=16, shuffle=True)
            val_loader   = DataLoader(CentralityToLabelDataset(val_pairs), batch_size=16)
            test_loader  = DataLoader(CentralityToLabelDataset(test_pairs), batch_size=16)

            # Initialize model (fixed: pass walk_length)
            model = Seq2SeqBERT(
                input_dim=features.shape[1],
                num_classes=num_classes,
                walk_length=walk_length,  # âœ… Correct argument
                hidden_dim=128,
                num_layers=2,
                nhead=4
            ).to(device)

            optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
            criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))

            # Training loop
            train_losses = []
            start_time = time.time()

            for epoch in range(num_epochs):
                model.train()
                total_loss = 0
                batch_count = 0

                for batch in train_loader:
                    x = batch["x"].to(device)
                    y = batch["y"].to(device)

                    # Teacher forcing input: [BOS, y[:-1]]
                    bos = torch.full((y.size(0), 1), fill_value=model.BOS_IDX,
                                     dtype=torch.long, device=device)
                    y_in = torch.cat([bos, y[:, :-1]], dim=1)

                    optimizer.zero_grad()
                    outputs = model(x, y_in)
                    loss = criterion(outputs.reshape(-1, num_classes), y.reshape(-1))
                    loss.backward()
                    optimizer.step()

                    total_loss += loss.item()
                    batch_count += 1

                avg_loss = total_loss / max(1, batch_count)
                train_losses.append(avg_loss)

            training_time = time.time() - start_time

            # Evaluation
            accuracy, precision, recall, f1, token_acc, seq_acc = evaluate_seq2seq_model(
                model, test_loader, device, num_classes)

            # Store results
            results.append({
                'model': 'Seq2SeqBERT',
                'num_walks': num_walks,
                'walk_length': walk_length,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'token_accuracy': token_acc,
                'sequence_accuracy': seq_acc,
                'training_time': training_time,
                'final_loss': train_losses[-1],
                'num_samples': len(train_pairs) + len(val_pairs) + len(test_pairs)
            })

            print(f"Results: Accuracy={accuracy:.4f}, F1={f1:.4f}, TokenAcc={token_acc:.4f}, Time={training_time:.2f}s")

    return pd.DataFrame(results)



# Function to visualize results for the second model
def visualize_seq2seq_results(results_df):
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('Seq2SeqBERT Performance Metrics vs. Number of Walks and Walk Length', fontsize=16)

    # Accuracy
    pivot_acc = results_df.pivot(index='num_walks', columns='walk_length', values='accuracy')
    sns.heatmap(pivot_acc, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[0, 0])
    axes[0, 0].set_title('Accuracy')

    # F1 Score
    pivot_f1 = results_df.pivot(index='num_walks', columns='walk_length', values='f1_score')
    sns.heatmap(pivot_f1, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[0, 1])
    axes[0, 1].set_title('F1 Score')

    # Token Accuracy
    pivot_token = results_df.pivot(index='num_walks', columns='walk_length', values='token_accuracy')
    sns.heatmap(pivot_token, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[0, 2])
    axes[0, 2].set_title('Token Accuracy')

    # Sequence Accuracy
    pivot_seq = results_df.pivot(index='num_walks', columns='walk_length', values='sequence_accuracy')
    sns.heatmap(pivot_seq, annot=True, fmt='.3f', cmap='YlOrRd', ax=axes[1, 0])
    axes[1, 0].set_title('Sequence Accuracy')

    # Training Time
    pivot_time = results_df.pivot(index='num_walks', columns='walk_length', values='training_time')
    sns.heatmap(pivot_time, annot=True, fmt='.1f', cmap='YlOrRd', ax=axes[1, 1])
    axes[1, 1].set_title('Training Time (s)')

    # Final Loss
    pivot_loss = results_df.pivot(index='num_walks', columns='walk_length', values='final_loss')
    sns.heatmap(pivot_loss, annot=True, fmt='.3f', cmap='YlOrRd_r', ax=axes[1, 2])
    axes[1, 2].set_title('Final Loss')

    plt.tight_layout()
    plt.show()

    # Line plots for trends
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # Accuracy by walk length for different numbers of walks
    for num_walks in results_df['num_walks'].unique():
        subset = results_df[results_df['num_walks'] == num_walks]
        axes[0, 0].plot(subset['walk_length'], subset['accuracy'], 'o-', label=f'{num_walks} walks')
    axes[0, 0].set_xlabel('Walk Length')
    axes[0, 0].set_ylabel('Accuracy')
    axes[0, 0].set_title('Accuracy vs. Walk Length')
    axes[0, 0].legend()
    axes[0, 0].grid(True)

    # Token vs Sequence Accuracy
    for num_walks in results_df['num_walks'].unique():
        subset = results_df[results_df['num_walks'] == num_walks]
        axes[0, 1].plot(subset['walk_length'], subset['token_accuracy'], 'o-', label=f'Token Acc ({num_walks} walks)')
        axes[0, 1].plot(subset['walk_length'], subset['sequence_accuracy'], 's--', label=f'Seq Acc ({num_walks} walks)')
    axes[0, 1].set_xlabel('Walk Length')
    axes[0, 1].set_ylabel('Accuracy')
    axes[0, 1].set_title('Token vs Sequence Accuracy')
    axes[0, 1].legend()
    axes[0, 1].grid(True)

    # Training time by number of walks
    for walk_length in results_df['walk_length'].unique():
        subset = results_df[results_df['walk_length'] == walk_length]
        axes[1, 0].plot(subset['num_walks'], subset['training_time'], 'o-', label=f'Length {walk_length}')
    axes[1, 0].set_xlabel('Number of Walks')
    axes[1, 0].set_ylabel('Training Time (s)')
    axes[1, 0].set_title('Training Time vs. Number of Walks')
    axes[1, 0].legend()
    axes[1, 0].grid(True)

    # Sample efficiency
    axes[1, 1].scatter(results_df['num_samples'], results_df['accuracy'], alpha=0.7)
    axes[1, 1].set_xlabel('Number of Samples')
    axes[1, 1].set_ylabel('Accuracy')
    axes[1, 1].set_title('Sample Efficiency')
    axes[1, 1].grid(True)

    # Add trend line for sample efficiency
    z = np.polyfit(results_df['num_samples'], results_df['accuracy'], 1)
    p = np.poly1d(z)
    axes[1, 1].plot(results_df['num_samples'], p(results_df['num_samples']), "r--", alpha=0.8)

    plt.tight_layout()
    plt.show()

    return results_df

# Main execution for the second model
if __name__ == "__main__":
    # Define parameter ranges to test
    num_walks_list = [5, 15, 25, 35, 45, 55, 65, 75]
    walk_lengths_list = [5, 10, 15, 20, 25, 30]

    # Run experiments
    print("Starting Seq2SeqBERT experiments...")
    results_df = run_seq2seq_experiments(num_walks_list, walk_lengths_list, num_epochs=10)

    # Display and visualize results
    print("\nExperiment Results:")
    print(results_df.to_string(index=False))

    # Visualize results
    visualize_seq2seq_results(results_df)

    # Find best parameters
    best_by_accuracy = results_df.loc[results_df['accuracy'].idxmax()]
    best_by_f1 = results_df.loc[results_df['f1_score'].idxmax()]
    best_by_token_acc = results_df.loc[results_df['token_accuracy'].idxmax()]
    best_by_seq_acc = results_df.loc[results_df['sequence_accuracy'].idxmax()]
    best_efficiency = results_df.loc[(results_df['accuracy'] / results_df['training_time']).idxmax()]

    print("\nBest Parameters for Seq2SeqBERT:")
    print(f"By Accuracy: {best_by_accuracy['num_walks']} walks, length {best_by_accuracy['walk_length']} (Accuracy: {best_by_accuracy['accuracy']:.4f})")
    print(f"By F1 Score: {best_by_f1['num_walks']} walks, length {best_by_f1['walk_length']} (F1: {best_by_f1['f1_score']:.4f})")
    print(f"By Token Accuracy: {best_by_token_acc['num_walks']} walks, length {best_by_token_acc['walk_length']} (Token Acc: {best_by_token_acc['token_accuracy']:.4f})")
    print(f"By Sequence Accuracy: {best_by_seq_acc['num_walks']} walks, length {best_by_seq_acc['walk_length']} (Seq Acc: {best_by_seq_acc['sequence_accuracy']:.4f})")
    print(f"By Efficiency: {best_efficiency['num_walks']} walks, length {best_efficiency['walk_length']} (Accuracy/Time: {best_efficiency['accuracy']/best_efficiency['training_time']:.4f})")